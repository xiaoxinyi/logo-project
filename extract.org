* [[https://github.com/BVLC/caffe/tree/85bb397acfd383a676c125c75d877642d6b39ff6/examples/feature_extraction][extract feature]]
** using caffe to extract features
  #+BEGIN_SRC sh
    find `pwd`/examples/images -type f -exec echo {} \; > examples/_temp/temp.txt
    sed "s/$/ 0/" examples/_temp/temp.txt > examples/_temp/file_list.txt
    cd $CAFFE
    ./build/tools/extract_features models/bvlc_reference_caffenet/bvlc_reference examples/_temp/imagenet_val.prototxt example/_temp/feature fc7 10 lmdb GPU 0
  #+END_SRC
** general command for extract feature using caffe
#+BEGIN_SRC sh
  extract_features pretrained_net_param  feature_extraction_proto_file \
  extract_feature_blob_name1[,name2,...]  save_feature_dataset_name1[,name2,...] \
  num_mini_batches  db_type  [CPU/GPU] [DEVICE_ID=0]
#+END_SRC
- 参数1是模型参数（.caffemodel）文件的路径。

- 参数2是描述网络结构的prototxt文件。程序会从参数1的caffemodel文件里找
  对应名称的layer读取参数。 

- 参数3是需要提取的blob名称，对应网络结构prototxt里的名称。blob名称可
  以有多个，用逗号分隔。每个blob提取出的特征会分开保存。 

- 参数4是保存提取出来的特征的数据库路径，可以有多个，和参数3中一一对应，
  以逗号分隔。如果用LMDB的话，路径必须是不存在的（已经存在的话要改名或
  者删除）。 


- 参数5是提取特征所需要执行的batch数量。这个数值和prototxt里DataLayer
  中的Caffe的DataLayer(或者ImageDataLayer)中的batch_size参数相乘，就是
  会被输入网络的总样本数。设置参数时需要确保batch_size *
  num_mini_batches等于需要提取特征的样本总数，否则提取的特征就会不够数
  或者是多了。 


- 参数6是保存特征使用的数据库类型，支持lmdb和leveldb两种(小写)。推荐使用
lmdb，因为lmdb的访问速度更快，还支持多进程同时读取。 

- 参数7决定使用GPU还是CPU，直接写对应的三个大写字母就行。省略不写的话默
认是CPU。 

- 参数8决定使用哪个GPU，在多GPU的机器上跑的时候需要指定。省略不写的话默
认使用0号GPU。 

注意事项
- 提取特征时，网络运行在Test模式下
    * Dropout层在Test模式下不起作用，不必担心dropout影响结果
    * Train和Test的参数写在同一个Prototxt里的时候，改参数的时候注意不
      要改错地方(比如有两个DataLayer的情况下) 
- 减去均值图像
    * 提取特征时，输入的图像要减去均值
    * 应该减去训练数据集的均值
- 提取哪一层
    * 不要提取Softmax网络的最后一层(如AlexNet的fc8)，因为最后一层已经
      是分类任务的输出，作为特征的可推广性不够好
** read from lmdb
  #+BEGIN_SRC python
    import numpy as np
    import caffe
    import lmdb
    from caffe.proto import caffe_pb2

    fea_lmdb = lmdb.open('featureA')
    lmdb_txn = fea_lmdb.begin()
    lmdb_cursor = lmdb_txn.cursor()
    features = []

    for key, value in lmdb_cursor:
        datum = caffe_pb2.Datum()
        datum.ParseFromString(value)
        data = caffe.io.datum_to_array(datum)
        features.append(data)

  #+END_SRC
